{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying a fine-tuned model with Model-As-Service Serverless\n",
    "\n",
    "This notebook shows how to deploy a fine-tuned model serverless on Azure AI Model-As-Service.\n",
    "\n",
    "#### Model\n",
    "We will use the model fine-tuned in the previous [1_finetune.ipynb](./1_finetune.ipynb) notebook.\n",
    "\n",
    "#### Pre-requisites\n",
    "- Same as in the [0_gen.ipynb](./0_gen.ipynb) notebook, you need to subscribe to the Marketplace offering. This should be done already but here is the [documentation](https://aka.ms/raft-llama-31-learn-deploy-405b) in case you worked around this in the previous notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U azure-ai-ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import (\n",
    "    DefaultAzureCredential,\n",
    "    InteractiveBrowserCredential,\n",
    ")\n",
    "from azure.ai.ml.entities import MarketplaceSubscription, ServerlessEndpoint\n",
    "\n",
    "try:\n",
    "    credential = DefaultAzureCredential()\n",
    "    credential.get_token(\"https://management.azure.com/.default\")\n",
    "except Exception as ex:\n",
    "    credential = InteractiveBrowserCredential()\n",
    "\n",
    "try:\n",
    "    client = MLClient.from_config(credential=credential)\n",
    "except:\n",
    "    print(\"Please create a workspace configuration file in the current directory.\")\n",
    "\n",
    "# Get AzureML workspace object.\n",
    "workspace = client._workspaces.get(client.workspace_name)\n",
    "workspace_id = workspace._workspace_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's figure out the name of the finetuned model from the shared state environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Variables passed by previous notebooks\n",
    "load_dotenv('.env.state')\n",
    "\n",
    "FINETUNED_MODEL_NAME = os.getenv(\"FINETUNED_MODEL_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fine-tuning job might still be training so let's wait until the model is ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import wait_for_model\n",
    "print(f\"Waiting for fine tuned model {FINETUNED_MODEL_NAME} to complete training...\")\n",
    "model = wait_for_model(client, FINETUNED_MODEL_NAME)\n",
    "print(f\"Model {FINETUNED_MODEL_NAME} is ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's subscribe to the model, this requires having accepted the provider's Marketplace terms at least once in the Model Catalog UI before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_id = model.properties['baseModelId']\n",
    "model_id = model.id\n",
    "subscription_name = base_model_id.split('/')[-1]\n",
    "print(f\"Subscribing to {subscription_name} for model ID {base_model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Asset ID required to deploy the model is not currently exposed through the Python SDK so we're constructing it using the information we have on hand.\n",
    "\n",
    "**Note**: as we're indirectly constructing the Asset ID blob storage path, the backend might change this and break this code. If this happens, you can figure out what the new expected form is by searching for the Asset ID field in the fine-tuned model's catalog page and adjust the template bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_asset_id = f\"azureml://locations/westus3/workspaces/{workspace_id}/{\"/\".join(model.id.split('/')[9:])}\"\n",
    "print(f\"Deploying model {model_asset_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marketplace_subscription = MarketplaceSubscription(\n",
    "    model_id=base_model_id,\n",
    "    name=subscription_name,\n",
    ")\n",
    "\n",
    "marketplace_subscription = client.marketplace_subscriptions.begin_create_or_update(\n",
    "    marketplace_subscription\n",
    ").result()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deploy the model as a serverless endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "guid = uuid.uuid4()\n",
    "short_guid = str(guid)[:4]\n",
    "endpoint_name=f\"{model.name}-{short_guid}\" # Name must be unique\n",
    "print(f\"Deploying model {model.name} as endpoint {endpoint_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Waiting for deployment to complete...\")\n",
    "serverless_endpoint = ServerlessEndpoint(\n",
    "    name=endpoint_name,\n",
    "    model_id=model_asset_id\n",
    ")\n",
    "\n",
    "created_endpoint = client.serverless_endpoints.begin_create_or_update(\n",
    "    serverless_endpoint\n",
    ").result()\n",
    "print(\"Deployment complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's extract the endpoint URL, name and keys and store them in the shared state to pass on to the next notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = client.serverless_endpoints.get(endpoint_name)\n",
    "endpoint_keys = client.serverless_endpoints.get_keys(endpoint_name)\n",
    "\n",
    "# Update the shared `.env.state` env file with the newly deployed finetuned model endpoint\n",
    "from utils import update_state\n",
    "update_state(\"FINETUNED_OPENAI_BASE_URL\", endpoint.scoring_uri)\n",
    "update_state(\"FINETUNED_OPENAI_API_KEY\", endpoint_keys.primary_key)\n",
    "update_state(\"FINETUNED_OPENAI_DEPLOYMENT\", endpoint.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that the finetuned model is deployed and available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = f\"{endpoint.scoring_uri}/v1/completions\"\n",
    "\n",
    "payload = {\n",
    "    \"max_tokens\": 1024,\n",
    "    \"prompt\": [ \"What do you know?\" ]\n",
    "}\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": endpoint_keys.primary_key\n",
    "}\n",
    "\n",
    "response = requests.post(url, json=payload, headers=headers)\n",
    "\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

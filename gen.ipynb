{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthetic data generation phase\n",
    "\n",
    "### Select the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ds_name = \"ucb-DEMO\"\n",
    "doc_path = \"sample_data/vampire-bats/surfing/Wakeboarding - Wikipedia.pdf\"\n",
    "ds_path = f\"dataset/{ds_name}\"\n",
    "print(\"Creating dataset: \" + ds_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_image(doc_path):\n",
    "    from wand.image import Image as WImage\n",
    "    from pathlib import Path\n",
    "    img = None\n",
    "    if Path(doc_path).exists() and Path(doc_path).is_file():\n",
    "        img = WImage(filename=doc_path)\n",
    "\n",
    "        # make background of img white\n",
    "        img.format = 'png'\n",
    "        img.background_color = 'white'\n",
    "        img.alpha_channel = 'remove'\n",
    "    return img\n",
    "get_pdf_image(doc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up the DEMO folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up demo folder only if it's a DEMO dataset\n",
    "if ds_path.endswith(\"DEMO\"):\n",
    "    import shutil\n",
    "    print(f\"Cleaning demo folder {ds_path}\")\n",
    "    shutil.rmtree(ds_path, ignore_errors=True)\n",
    "    print(f\"Cleaning demo checkpoints folder {ds_path}\")\n",
    "    shutil.rmtree(ds_path + \"-checkpoints\", ignore_errors=True)\n",
    "    print(f\"Cleaning demo files folder {ds_path}\")\n",
    "    shutil.rmtree(ds_path + \"-files\", ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Q/A/CoT fine-tuning dataset using RAFT from the domain specific documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python3 .gorilla/raft/raft.py \\\n",
    "    --datapath \"$doc_path\" \\\n",
    "    --output $ds_path \\\n",
    "    --distractors 3 \\\n",
    "    --doctype pdf \\\n",
    "    --chunk_size 512 \\\n",
    "    --questions 1 \\\n",
    "    --workers 2 \\\n",
    "    --system-prompt-key llama \\\n",
    "    --completion_model Meta-Llama-3-70B-Instruct \\\n",
    "    --embedding_model text-embedding-ada-002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training, validation and evaluation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raft_arrow_file = f\"{ds_path}/data-00000-of-00001.arrow\"\n",
    "dataset_path = f\"{ds_path}-files/{ds_name}-full.jsonl\"\n",
    "dataset_path_hf = f\"{ds_path}-files/{ds_name}-hf.full.jsonl\"\n",
    "\n",
    "dataset_path_hf_train = f\"{ds_path}-files/{ds_name}-hf.train.jsonl\"\n",
    "dataset_path_hf_valid = f\"{ds_path}-files/{ds_name}-hf.valid.jsonl\"\n",
    "dataset_path_hf_eval = f\"{ds_path}-files/{ds_name}-hf.eval.jsonl\"\n",
    "\n",
    "dataset_path_ft_train = f\"{ds_path}-files/{ds_name}-ft.train.jsonl\"\n",
    "dataset_path_ft_valid = f\"{ds_path}-files/{ds_name}-ft.valid.jsonl\"\n",
    "\n",
    "print(f\"Reading arrow file {raft_arrow_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export dataset to JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python .gorilla/raft/format.py \\\n",
    "    --input $raft_arrow_file \\\n",
    "    --output $dataset_path_hf \\\n",
    "    --output-format hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_full_df = pd.read_json(dataset_path_hf, lines=True)\n",
    "hf_full_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's look at a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "from random import randint\n",
    "sample_idx = randint(0, len(hf_full_df) - 1)\n",
    "sample = hf_full_df.iloc[sample_idx]\n",
    "instruction_md = sample.instruction.replace(\"<DOCUMENT>\", \"`<DOCUMENT>`\").replace(\"</DOCUMENT>\", \"`</DOCUMENT>`\")\n",
    "oracle_context_md = sample.oracle_context.replace(\"<DOCUMENT>\", \"`<DOCUMENT>`\").replace(\"</DOCUMENT>\", \"`</DOCUMENT>`\")\n",
    "sample_answer_md = sample.cot_answer.replace(\"<ANSWER>\", \"`<ANSWER>`\").replace(\"##begin_quote##\", \"`##begin_quote##`\").replace(\"##end_quote##\", \"`##end_quote##`\")\n",
    "display(Markdown(f\"## Oracle Context\\n{oracle_context_md}\\n\\n## Question\\n{sample.question}\\n\\n## CoT Answer\\n{sample_answer_md}\\n\\n## Instruction\\n{instruction_md}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into 80%/10%/10%\n",
    "import numpy as np\n",
    "samples_count = len(hf_full_df)\n",
    "hf_train_df, hf_valid_df, hf_eval_df = np.split(hf_full_df, [int(.8*samples_count), int(.9*samples_count)])\n",
    "hf_train_df.to_json(dataset_path_hf_train, orient=\"records\", lines=True)\n",
    "hf_valid_df.to_json(dataset_path_hf_valid, orient=\"records\", lines=True)\n",
    "hf_eval_df.to_json(dataset_path_hf_eval, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export training and validation datasets into JSONL format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python .gorilla/raft/format.py \\\n",
    "    --input $dataset_path_hf_train \\\n",
    "    --input-type jsonl \\\n",
    "    --output $dataset_path_ft_train \\\n",
    "    --output-format completion \\\n",
    "    --output-completion-prompt-column text\\\n",
    "    --output-completion-completion-column ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! python .gorilla/raft/format.py \\\n",
    "    --input $dataset_path_hf_valid \\\n",
    "    --input-type jsonl \\\n",
    "    --output $dataset_path_ft_valid \\\n",
    "    --output-format completion \\\n",
    "    --output-completion-prompt-column text\\\n",
    "    --output-completion-completion-column ground_truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path_ft_valid_df = pd.read_json(dataset_path_ft_valid, lines=True)\n",
    "dataset_path_ft_valid_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep the evaluation split aside"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need to format the evaluation dataset for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_json(dataset_path_hf_eval, lines=True).head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
